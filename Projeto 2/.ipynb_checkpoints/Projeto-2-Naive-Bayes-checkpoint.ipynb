{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução:\n",
    "\n",
    "Para o projeto 2 de ciência dos dados tinhamos que construir um classificador automático de sentimento sobre um produto no Twitter. \n",
    "\n",
    "Decidimos então que que fazer uma análise de sentimento do próprio twitter poderia ser algo bastante interessante já que a parcela da população sobre a qual estamos recolhendo dados entende a plataforma em que está mechendo (Twitter) e, já que a usa, presumimos que gosta desta.\n",
    "\n",
    "Como vimos na disciplina de Co-design de aplicativos, o melhor tipo de feedback é aquele dado por clientes que amam seu produto, porém, estão muito insatisfeitos com algum aspecto dele. Isso porque dentro desse feedback há uma admiração e uma crítica ao produto, assim, podendo observar os aspectos a manter e a mudar em futuras iterações.\n",
    "\n",
    "Dessa forma, nesse documento discutiremos os desdobramentos da nossa análise sobre a relevância dos tweets sobre o próprio twitter.\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "###### Projeto 2 Ciência dos Dados:\n",
    "###### Gustavo Berger e Rafael dos Santos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to /Users/Gustavo/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#======================================= Imports =======================================\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import nltk\n",
    "nltk.download('rslp')\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "dados= pd.read_excel(\"tweets_certos_3.0.xlsx\")\n",
    "dados_teste= pd.read_excel(\"tweets_certos_3.0.xlsx\",sheet_name=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======================================= Função para limpar os tweets =======================================\n",
    "def limpa_tweet(tweet):\n",
    "    tweet = tweet.replace(\" por \", \" \")\n",
    "    tweet = tweet.replace(\" do \", \" \")\n",
    "    tweet = tweet.replace(\" da \", \" \")\n",
    "    tweet = tweet.replace(\" de \", \" \")\n",
    "    tweet = tweet.replace(\" '\", \"\")\n",
    "    tweet = tweet.replace(\"' \", \"\")\n",
    "    tweet = tweet.replace(\"#\", \"\")\n",
    "    tweet = tweet.replace(\" à \", \" \")\n",
    "    tweet = tweet.replace(\" aos \", \" \")\n",
    "    tweet = tweet.replace(\" o \", \" \")\n",
    "    tweet = tweet.replace(\" a \", \" \")\n",
    "    tweet = tweet.replace(\" e \", \" \")\n",
    "    tweet = tweet.replace(\"!\", \" \")\n",
    "    tweet = tweet.replace(\"?\", \" \")\n",
    "    tweet = tweet.replace(\"(\", \" \")\n",
    "    tweet = tweet.replace(\")\", \" \")\n",
    "    tweet = tweet.replace(\" rt \", \" \")\n",
    "    tweet = tweet.replace(\"rt \", \" \")\n",
    "\n",
    "    tweet = tweet.lower()\n",
    "    tweet = tweet.split()\n",
    "    \n",
    "    for palavra in tweet:\n",
    "        if '@' in palavra or 'https' in palavra:\n",
    "            tweet.remove(palavra)\n",
    "\n",
    "                          \n",
    "    tweets_stemizados = []\n",
    "    for palavra in tweet:\n",
    "        tweets_stemizados.append(stemmer.stem(palavra))\n",
    "\n",
    "    return tweets_stemizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================== Contagem da quantidade das classificações  =======================================\n",
    "total_0 = dados['Treinamento'][dados['rel/irrel'] == 0].count()\n",
    "total_1 = dados['Treinamento'][dados['rel/irrel'] == 1].count()\n",
    "\n",
    "total = total_0 + total_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidade de Irrelevante: 31.79%\n",
      "Probabilidade de Relevante: 68.21%\n"
     ]
    }
   ],
   "source": [
    "#======================================= Cálculo das probs. pelas contagens =======================================\n",
    "p_0 = total_0 / total\n",
    "p_1 = total_1 / total\n",
    "\n",
    "print(\"Probabilidade de Irrelevante: {:.2f}%\".format(p_1*100))\n",
    "print(\"Probabilidade de Relevante: {:.2f}%\".format(p_0*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================== Criação de listas, dicionários e variáveis =====================================\n",
    "palavras_relevantes = []\n",
    "palavras_irrelevantes = []\n",
    "\n",
    "frequencia_irrelevantes = {}\n",
    "frequencia_relevantes = {}\n",
    "\n",
    "n_relevante = 0\n",
    "n_irrelevante = 0\n",
    "\n",
    "\n",
    "#============================== loop para limpar os tweets e contar as palavras ============================\n",
    "i = 0\n",
    "for avaliacao in dados['rel/irrel']:\n",
    "    tweet_limpo = limpa_tweet(dados['Treinamento'][i])\n",
    "    for palavra in tweet_limpo:\n",
    "        if avaliacao == 1:\n",
    "            if palavra not in palavras_irrelevantes:\n",
    "                palavras_irrelevantes.append(palavra)\n",
    "                frequencia_irrelevantes[palavra] = 1\n",
    "            else:\n",
    "                frequencia_irrelevantes[palavra] += 1\n",
    "            n_irrelevante += 1\n",
    "            \n",
    "        else:\n",
    "            if palavra not in palavras_relevantes:\n",
    "                palavras_relevantes.append(palavra)\n",
    "                frequencia_relevantes[palavra] = 1\n",
    "            else:\n",
    "                frequencia_relevantes[palavra] += 1\n",
    "            n_relevante += 1\n",
    "            \n",
    "    i += 1\n",
    "    \n",
    "n_total = n_relevante + n_irrelevante\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======================================= Função para calcular a probabilidade =======================================\n",
    "def calc_prob(tweet, dic_palavras, p, n_palavras):\n",
    "    prob = p\n",
    "    total = n_palavras\n",
    "    tweet_limpo = limpa_tweet(tweet)\n",
    "    for palavra in tweet_limpo:\n",
    "        ocorrencia = 1\n",
    "        if palavra in dic_palavras:\n",
    "            ocorrencia += dic_palavras[palavra]\n",
    "        prob += np.log(ocorrencia/(total + n_total))\n",
    "    return prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======================================= Função para escolher a classificação =======================================\n",
    "def comparador_prob(prob_0, prob_1):\n",
    "    if prob_0 > prob_1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digite seu tweet de teste: k\n",
      "['k']\n",
      "relevante\n"
     ]
    }
   ],
   "source": [
    "#=========================================== Teste de funcionamento ==============================================\n",
    "tweet = input('Digite seu tweet de teste: ')\n",
    "prob_1 = calc_prob(tweet, frequencia_irrelevantes, p_1, n_irrelevante)\n",
    "prob_0 = calc_prob(tweet, frequencia_relevantes, p_0, n_relevante)\n",
    "resp = comparador_prob(prob_0, prob_1)\n",
    "print(limpa_tweet(tweet))\n",
    "if resp == 1:\n",
    "    print('irrelevante')\n",
    "if resp == 0:\n",
    "    print('relevante')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================= criação da coluna de previsão no datasheet ==================================\n",
    "coluna_previsao = []\n",
    "for tweet in dados_teste['Teste']:\n",
    "    prob_1 = calc_prob(tweet, frequencia_irrelevantes, p_1, n_irrelevante)\n",
    "    prob_0 = calc_prob(tweet, frequencia_relevantes, p_0, n_relevante)\n",
    "    coluna_previsao.append(comparador_prob(prob_0, prob_1))\n",
    "    \n",
    "dados_teste['Previsão'] = coluna_previsao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de Acerto: 71.00%\n"
     ]
    }
   ],
   "source": [
    "#====================================== Cálculo da porcentagem de acerto ===========================================\n",
    "acertos = 0\n",
    "i = 0\n",
    "for avaliacao in dados_teste['rel/irrel']:\n",
    "    if avaliacao == dados_teste['Previsão'][i]:\n",
    "        acertos += 1\n",
    "    i += 1\n",
    "    \n",
    "print(\"Porcentagem de Acerto: {:.2f}%\".format(100*acertos/len(dados_teste)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusão:\n",
    "\n",
    "\n",
    "### Sobre o código escrito para o Twitter:\n",
    "\n",
    "   Por fim, nosso classificador automático de sentimeto tem uma acurácia relaivamente alta (71%), o que se mostra como uma vantagem na hora de análisar os resultados obtidos.\n",
    "   \n",
    "   Chegamos à conclusão de que os usuários do twitter não estão satisfeitos com a nova atualização da plataforma, já que o uptade fez o aplicativo ficar muito parecido com o Facebook, característica que os usuários se demonstraram instatisfeitos, com isso, garantimos à empresa twitter um grande feedback sobre possíveis melhorias. Porém o nosso espaço amostral se demonstrou muito reduzido à comentários negativos sobre a nova atualização. Dessa forma, para obter um feedback completo de como melhorar em futuras atualizações seria necessário fazer uma análise mais detalhada de comentários positívos. Assim, observar uma amostra em um tempo diferente seria essencial para garantir uma maior porcentagem de comentários positívos.\n",
    "   \n",
    "   Além disso, para aperfeiçoar o nosso trabalho gostariamos de refinar o código considerando sarcasmos e ironias, já que durante nossa classificação, essas informações foram julgadas em seu sentido literal. \n",
    "   \n",
    "  <br>\n",
    "   \n",
    "### Sobre o Algorítimo:\n",
    "\n",
    "   O classificador de Naive-Bayes é um algorítmo extremamente potente, com diversas aplicações em análise de dados. Um exemplo dessas aplicações seria a probabilidade de uma pessoa comprar um computador novo dado a renda média dela. Isso pode ter altos impactos em pesquisas de público alvo para empresas de computação e em possíveis estratégias de marketing.\n",
    "  \n",
    "   Porém, apesar de todo seu potencial, como quase todo classificador apresenta algumas limitações de uso, tais como a impossibilidade de alimentar a sua própria base de treinamento automaticamente com o prórpio classificador. Isto ocorre por conta da acumulação do erro do classificador, isto é, realizar esta atividade iria aumentar a porcentagem de erro do classificador a cada nova iteração."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
