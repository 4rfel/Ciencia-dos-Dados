{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 19/Set até às 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terá uma rubrica diferenciada.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Obrigatório para grupos de 3 alunos:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to /Users/Gustavo/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import nltk\n",
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.RSLPStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpa_tweet(tweet):\n",
    "    tweet = tweet.replace(\"@\", \" \")\n",
    "    tweet = tweet.replace(\" por \", \" \")\n",
    "    tweet = tweet.replace(\" do \", \" \")\n",
    "    tweet = tweet.replace(\" da \", \" \")\n",
    "    tweet = tweet.replace(\" de \", \" \")\n",
    "    tweet = tweet.replace(\" '\", \"\")\n",
    "    tweet = tweet.replace(\"' \", \"\")\n",
    "    tweet = tweet.replace(\" à \", \" \")\n",
    "    tweet = tweet.replace(\" aos \", \" \")\n",
    "    tweet = tweet.replace(\" o \", \" \")\n",
    "    tweet = tweet.replace(\" a \", \" \")\n",
    "    tweet = tweet.replace(\" e \", \" \")\n",
    "    tweet = tweet.replace(\"!\", \" \")\n",
    "    tweet = tweet.replace(\"?\", \" \")\n",
    "    tweet = tweet.replace(\"(\", \" \")\n",
    "    tweet = tweet.replace(\")\", \" \")\n",
    "    tweet = tweet.replace(\" rt \", \" \")\n",
    "    tweet = tweet.replace(\"rt \", \" \")\n",
    "\n",
    "    tweet = tweet.lower()\n",
    "    tweet = tweet.split()\n",
    "    \n",
    "    for palavra in tweet:\n",
    "        if '@' in palavra or 'https' in palavra:\n",
    "            tweet.remove(palavra)\n",
    "\n",
    "                          \n",
    "    tweets_stemizados = []\n",
    "    for palavra in tweet:\n",
    "        tweets_stemizados.append(stemmer.stem(palavra))\n",
    "\n",
    "    return tweets_stemizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_excel('tweets_certos_2.0.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_0 = dados.avaliacao[dados.avaliacao == 0].count()\n",
    "total_1 = dados.avaliacao[dados.avaliacao == 1].count()\n",
    "total_2 = dados.avaliacao[dados.avaliacao == 2].count()\n",
    "\n",
    "total = total_0 + total_1 + total_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidade de Negativo: 52.65%\n",
      "Probabilidade de Irrelevante: 31.79%\n",
      "Probabilidade de Positivo: 15.56%\n"
     ]
    }
   ],
   "source": [
    "p_0 = total_0 / total\n",
    "p_1 = total_1 / total\n",
    "p_2 = total_2 / total\n",
    "\n",
    "print(\"Probabilidade de Negativo: {:.2f}%\".format(p_0*100))\n",
    "print(\"Probabilidade de Irrelevante: {:.2f}%\".format(p_1*100))\n",
    "print(\"Probabilidade de Positivo: {:.2f}%\".format(p_2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-983c467f0b1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mavaliacao\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdados\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avaliacao'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtweet_limpo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlimpa_tweet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdados\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Treinamento'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mavaliacao\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpalavra\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweet_limpo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-32cd276dbe99>\u001b[0m in \u001b[0;36mlimpa_tweet\u001b[0;34m(tweet)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpalavra\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'@'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpalavra\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'https'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpalavra\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpalavra\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "palavras_boas = []\n",
    "palavras_ruins = []\n",
    "palavras_neutras = []\n",
    "\n",
    "frequencia_boas = {}\n",
    "frequencia_ruins = {}\n",
    "frequencia_neutras = {}\n",
    "\n",
    "n_boas = 0\n",
    "n_ruins = 0\n",
    "n_neutras = 0\n",
    "\n",
    "i = 0\n",
    "for avaliacao in dados['avaliacao']:\n",
    "    tweet_limpo = limpa_tweet(dados['Treinamento'][i])\n",
    "    if avaliacao == 0:\n",
    "        for palavra in tweet_limpo:\n",
    "            if palavra not in palavras_ruins:\n",
    "                palavras_ruins.append(palavra)\n",
    "                frequencia_ruins[palavra] = 1\n",
    "            else:\n",
    "                frequencia_ruins[palavra] += 1\n",
    "            n_ruins += 1\n",
    "            \n",
    "    if avaliacao == 1:\n",
    "        for palavra in tweet_limpo:\n",
    "            if palavra not in palavras_neutras:\n",
    "                palavras_neutras.append(palavra)\n",
    "                frequencia_neutras[palavra] = 1\n",
    "            else:\n",
    "                frequencia_neutras[palavra] += 1\n",
    "            n_neutras += 1\n",
    "            \n",
    "    if avaliacao == 2:\n",
    "        for palavra in tweet_limpo:\n",
    "            if palavra not in palavras_boas:\n",
    "                palavras_boas.append(palavra)\n",
    "                frequencia_boas[palavra] = 1\n",
    "            else:\n",
    "                frequencia_boas[palavra] += 1\n",
    "            n_boas += 1\n",
    "            \n",
    "    i += 1\n",
    "n_total = n_boas + n_neutras + n_ruins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prob(tweet, dic_palavras, p, n_palavras):\n",
    "    prob = p\n",
    "    total = n_palavras #+ alpha*d\n",
    "    tweet_limpo = limpa_tweet(tweet)\n",
    "    for palavra in tweet_limpo:\n",
    "        ocorrencia = 1 #*alpha\n",
    "        if palavra in dic_palavras:\n",
    "            ocorrencia += dic_palavras[palavra]\n",
    "            \n",
    "        prob *= (ocorrencia/n_total)\n",
    "    return prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparador_prob(prob_0, prob_1, prob_2):\n",
    "    if prob_0 > prob_1 and prob_0 > prob_2:\n",
    "        return 0\n",
    "    elif prob_1 > prob_0 and prob_1 > prob_2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_teste = pd.read_excel(\"tweets_certos_2.0.xlsx\", sheet_name=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coluna_previsao = []\n",
    "for tweet in dados_teste['Teste']:\n",
    "    prob_0 = calc_prob(tweet, frequencia_ruins, p_0, n_ruins)\n",
    "    prob_1 = calc_prob(tweet, frequencia_neutras, p_1, n_neutras)\n",
    "    prob_2 = calc_prob(tweet, frequencia_boas, p_2, n_boas)\n",
    "    coluna_previsao.append(comparador_prob(prob_0, prob_1, prob_2))\n",
    "    \n",
    "dados_teste['Previsão'] = coluna_previsao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acertos = 0\n",
    "i = 0\n",
    "for avaliacao in dados_teste['avaliacao']:\n",
    "    if avaliacao == dados_teste['Previsão'][i]:\n",
    "        acertos += 1\n",
    "    i += 1\n",
    "    \n",
    "print(\"Porcentagem de Acerto: {:.2f}%\".format(100*acertos/len(dados_teste)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dados_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
